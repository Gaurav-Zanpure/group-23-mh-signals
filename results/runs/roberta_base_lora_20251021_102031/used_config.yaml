data:
  data_cfg: configs/data.yaml
logging:
  run_name: roberta_base_lora
  save_dir: results/runs
lora:
  lora_alpha: 64
  lora_dropout: 0.1
  r: 32
  target_modules:
  - query
  - value
  - key
  - dense
model:
  max_length: 512
  name: roberta-large
training:
  epochs: 20
  eval_batch_size: 32
  learning_rate: 1e-5
  output_dir: models/checkpoints/
  seed: 42
  threshold: 0.35
  train_batch_size: 16
  weight_decay: 0.05
