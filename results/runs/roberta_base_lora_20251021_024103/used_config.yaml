data:
  data_cfg: configs/data.yaml
logging:
  run_name: roberta_base_lora
  save_dir: results/runs
lora:
  lora_alpha: 32
  lora_dropout: 0.1
  r: 16
  target_modules:
  - query
  - value
  - key
  - dense
model:
  max_length: 512
  name: roberta-large
training:
  epochs: 6
  eval_batch_size: 24
  learning_rate: 2e-5
  output_dir: models/checkpoints/
  seed: 42
  threshold: 0.25
  train_batch_size: 6
  weight_decay: 0.05
